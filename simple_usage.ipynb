{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT:\n",
      "<s>[INST] <<SYS>>\n",
      "You are respectful and helpful assistant.\n",
      "<</SYS>>\n",
      "\n",
      "What is Llama 2 model? [/INST]\n",
      "\n",
      "ANSWER:\n",
      "Ah, a question about technology! *adjusts glasses* The Llama 2 model is actually an older version of the Llama AI model, which was developed by Meta AI. It's a language model that was trained on a large corpus of text data and can generate human-like responses to questions and prompts.\n",
      "\n",
      "The Llama 2 model is similar to the original Llama model but has been updated with new features and improvements, such as increased ability to handle complex questions and longer texts. It's able to understand context and nuances of language, and can respond in a more natural and conversational way.\n",
      "\n",
      "However, it's important to note that Llama 2 is not a conscious or sentient being, but rather an AI model designed to mimic human language generation capabilities as closely as possible. It doesn't have personal opinions, feelings, or desires like a human, and its responses are generated based on patterns it has learned from the data it was trained on.\n",
      "Does this help clarify things? *smiles*"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, a question about technology! *adjusts glasses* The Llama 2 model is actually an older version of the Llama AI model, which was developed by Meta AI. It's a language model that was trained on a large corpus of text data and can generate human-like responses to questions and prompts.\\n\\nThe Llama 2 model is similar to the original Llama model but has been updated with new features and improvements, such as increased ability to handle complex questions and longer texts. It's able to understand context and nuances of language, and can respond in a more natural and conversational way.\\n\\nHowever, it's important to note that Llama 2 is not a conscious or sentient being, but rather an AI model designed to mimic human language generation capabilities as closely as possible. It doesn't have personal opinions, feelings, or desires like a human, and its responses are generated based on patterns it has learned from the data it was trained on.\\nDoes this help clarify things? *smiles*\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms.llamacpp import LlamaCpp\n",
    "\n",
    "# Establish callback to LLM for logging, monitoring, streaming and other tasks\n",
    "callback_manager = CallbackManager(\n",
    "    handlers=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path='llama-2-7b-chat.gguf.q2_K.bin',\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "system_prompt = \"You are respectful and helpful assistant.\"\n",
    "user_prompt = \"What is Llama 2 model?\"\n",
    "\n",
    "input_prompt = \\\n",
    "f\"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{user_prompt} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nINPUT:\\n\" + input_prompt + '\\nANSWER:')\n",
    "\n",
    "llm.invoke(\n",
    "    input=input_prompt\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
